# ===========================================
# SYNESIS CONFIGURATION
# ===========================================
# Copy this file to .env and fill in your values
# Generate secrets with: openssl rand -hex 32

# Environment
SYNESIS_ENV=development
SYNESIS_DEBUG=true
SYNESIS_LOG_LEVEL=INFO

# ===========================================
# DATABASE (PostgreSQL + TimescaleDB)
# ===========================================
DB_PASSWORD=  # REQUIRED: Generate with: openssl rand -hex 32
DATABASE_URL=postgresql+asyncpg://synesis:${DB_PASSWORD}@localhost:5435/synesis

# ===========================================
# REDIS
# ===========================================
REDIS_PASSWORD=  # REQUIRED: Generate with: openssl rand -hex 32
REDIS_URL=redis://:${REDIS_PASSWORD}@localhost:6379

# ===========================================
# N8N (Workflow Automation)
# ===========================================
# Required for n8n encryption and JWT
N8N_ENCRYPTION_KEY=  # REQUIRED: Generate with: openssl rand -hex 32
N8N_USER_MANAGEMENT_JWT_SECRET=  # REQUIRED: Generate with: openssl rand -hex 32

# ===========================================
# TELEGRAM (Ingestion)
# ===========================================
# Get from https://my.telegram.org
TELEGRAM_API_ID=
TELEGRAM_API_HASH=
TELEGRAM_SESSION_NAME=synesis
TELEGRAM_CHANNELS=

# ===========================================
# TELEGRAM (Notifications)
# ===========================================
# Create a bot via @BotFather and get the token
# Get chat ID by messaging your bot and checking:
# https://api.telegram.org/bot<TOKEN>/getUpdates
TELEGRAM_BOT_TOKEN=
TELEGRAM_CHAT_ID=

# ===========================================
# TWITTER/X
# ===========================================
# Using TwitterAPI.io (or similar third-party provider)
TWITTERAPI_API_KEY=
TWITTER_API_BASE_URL=https://api.twitterapi.io
# JSON array of usernames to follow
TWITTER_ACCOUNTS=["DeItaone","KobeissiLetter","Fxhedgers","zerohedge"]

# Source categorization (affects urgency in Flow 1)
# News accounts = high urgency (breaking news, act fast)
TWITTER_NEWS_ACCOUNTS=["DeItaone","realDonaldTrump"]
# Analysis accounts = normal urgency (insights, consider)
TWITTER_ANALYSIS_ACCOUNTS=["elonmusk","NickTimiraos","charliebilello","KobeissiLetter"]

# ===========================================
# REDDIT (Flow 2 - Sentiment Intelligence)
# ===========================================
# JSON array of subreddits to monitor (no r/ prefix needed)
REDDIT_SUBREDDITS=["wallstreetbets","stocks","StockMarket","options","thetagang"]
REDDIT_POLL_INTERVAL=21600  # 6 hours in seconds

# ===========================================
# POLYMARKET
# ===========================================
POLYMARKET_API_KEY=
POLYMARKET_API_SECRET=
POLYMARKET_PRIVATE_KEY=
POLYMARKET_CHAIN_ID=137

# ===========================================
# LLM PROVIDER
# ===========================================
# Provider: "anthropic" or "openai" (for ZAI, use "openai" with custom base URL)
LLM_PROVIDER=anthropic

# Anthropic (Claude)
ANTHROPIC_API_KEY=

# OpenAI / ZAI (OpenAI-compatible)
# For ZAI: set OPENAI_BASE_URL=https://api.z.ai/api/coding/paas/v4
OPENAI_API_KEY=
OPENAI_BASE_URL=

# Model names
# Anthropic: claude-3-5-haiku-20241022, claude-sonnet-4-20250514
# ZAI: glm-4.7, glm-4.7-FlashX, glm-4.7-Flash (free)
LLM_MODEL=claude-3-5-haiku-20241022
LLM_MODEL_SMART=claude-sonnet-4-20250514

# ===========================================
# WEB SEARCH (for LLM enrichment)
# ===========================================
# SearXNG (self-hosted, primary) - start with: docker compose up -d searxng
# No API key needed, no rate limits. Set to empty to disable.
SEARXNG_URL=http://localhost:8080
# Exa API - fallback for financial news (https://exa.ai)
EXA_API_KEY=
# Brave Search API - fallback (https://brave.com/search/api)
BRAVE_API_KEY=

# ===========================================
# CRAWL4AI (Web Crawling)
# ===========================================
# Start with: docker compose up -d crawl4ai
CRAWL4AI_URL=http://localhost:11235

# ===========================================
# DATA PROVIDERS
# ===========================================
# Provider selection (allows swapping data sources)
PRICE_PROVIDER=finnhub
TICKER_PROVIDER=finnhub
FUNDAMENTALS_PROVIDER=finnhub  # Options: finnhub, none

# Finnhub (Stock Price Data)
# Get API key from https://finnhub.io (free tier: 60 calls/min)
FINNHUB_API_KEY=

# ===========================================
# FACTSET (SQL Server - Optional)
# ===========================================
# Only needed if using FactSet data feeds
SQLSERVER_HOST=
SQLSERVER_PORT=1433
SQLSERVER_DATABASE=
SQLSERVER_USER=
SQLSERVER_PASSWORD=

# ===========================================
# PROCESSING (Advanced)
# ===========================================
# Concurrency settings (defaults work well for most setups)
PROCESSING_WORKERS=5
PROCESSING_QUEUE_SIZE=100
WEB_SEARCH_MAX_QUERIES=2
POLYMARKET_MAX_KEYWORDS=5

# Output directory for signals
SIGNALS_OUTPUT_DIR=output/signals
