# ===========================================
# SYNESIS CONFIGURATION
# ===========================================
# Copy this file to .env and fill in your values
# Generate secrets with: openssl rand -hex 32
#
# ---- Docker Compose ----
# When running via `docker compose up`, swap these URLs:
#   DATABASE_URL = postgresql+asyncpg://synesis:${DB_PASSWORD}@timescaledb:5432/synesis
#   REDIS_URL    = redis://:${REDIS_PASSWORD}@redis:6379
#   SEARXNG_URL  = http://searxng:8080
#   CRAWL4AI_URL = http://crawl4ai:11235

# Environment
SYNESIS_ENV=development
SYNESIS_DEBUG=true
SYNESIS_LOG_LEVEL=INFO

# ===========================================
# DATABASE (PostgreSQL + TimescaleDB)
# ===========================================
DB_PASSWORD=  # REQUIRED: Generate with: openssl rand -hex 32
DATABASE_URL=postgresql+asyncpg://synesis:${DB_PASSWORD}@localhost:5435/synesis

# ===========================================
# REDIS
# ===========================================
REDIS_PASSWORD=  # REQUIRED: Generate with: openssl rand -hex 32
REDIS_URL=redis://:${REDIS_PASSWORD}@localhost:6379

# ===========================================
# N8N (Workflow Automation)
# ===========================================
# Required for n8n encryption and JWT
N8N_ENCRYPTION_KEY=  # REQUIRED: Generate with: openssl rand -hex 32
N8N_USER_MANAGEMENT_JWT_SECRET=  # REQUIRED: Generate with: openssl rand -hex 32

# ===========================================
# TELEGRAM (Ingestion)
# ===========================================
# Get from https://my.telegram.org
TELEGRAM_API_ID=
TELEGRAM_API_HASH=
TELEGRAM_SESSION_NAME=synesis
TELEGRAM_CHANNELS=

# ===========================================
# TELEGRAM (Notifications)
# ===========================================
# Create a bot via @BotFather and get the token
# Get chat ID by messaging your bot and checking:
# https://api.telegram.org/bot<TOKEN>/getUpdates
TELEGRAM_BOT_TOKEN=
TELEGRAM_CHAT_ID=

# ===========================================
# NOTIFICATION CHANNEL
# ===========================================
# Which channel to send notifications to: "telegram" or "discord"
NOTIFICATION_CHANNEL=telegram

# ===========================================
# DISCORD (Notifications)
# ===========================================
# Create a webhook in Discord: Server Settings > Integrations > Webhooks
DISCORD_WEBHOOK_URL=

# ===========================================
# TWITTER/X
# ===========================================
# Using TwitterAPI.io (or similar third-party provider)
TWITTERAPI_API_KEY=
TWITTER_API_BASE_URL=https://api.twitterapi.io
# JSON array of usernames to follow
TWITTER_ACCOUNTS=["DeItaone","KobeissiLetter","Fxhedgers","zerohedge"]


# ===========================================
# POLYMARKET
# ===========================================
POLYMARKET_API_KEY=
POLYMARKET_API_SECRET=
POLYMARKET_PRIVATE_KEY=
POLYMARKET_CHAIN_ID=137

# ===========================================
# LLM PROVIDER
# ===========================================
# Provider: "anthropic" or "openai" (for ZAI, use "openai" with custom base URL)
LLM_PROVIDER=anthropic

# Anthropic (Claude)
ANTHROPIC_API_KEY=

# OpenAI / ZAI (OpenAI-compatible)
# For ZAI: set OPENAI_BASE_URL=https://api.z.ai/api/coding/paas/v4
OPENAI_API_KEY=
OPENAI_BASE_URL=

# Model names
# Anthropic: claude-3-5-haiku-20241022, claude-sonnet-4-20250514
# ZAI: glm-4.7, glm-4.7-FlashX, glm-4.7-Flash (free)
LLM_MODEL=claude-3-5-haiku-20241022
LLM_MODEL_SMART=claude-sonnet-4-20250514

# ===========================================
# WEB SEARCH (for LLM enrichment)
# ===========================================
# SearXNG (self-hosted, primary) - start with: docker compose up -d searxng
# No API key needed, no rate limits. Set to empty to disable.
SEARXNG_URL=http://localhost:8080
# Exa API - fallback for financial news (https://exa.ai)
EXA_API_KEY=
# Brave Search API - fallback (https://brave.com/search/api)
BRAVE_API_KEY=

# ===========================================
# CRAWL4AI (Web Crawling)
# ===========================================
# Start with: docker compose up -d crawl4ai
CRAWL4AI_URL=http://localhost:11235

# ===========================================
# SEC EDGAR (free, no key required)
# ===========================================
SEC_EDGAR_USER_AGENT=Synesis synesis@example.com
SEC_EDGAR_CACHE_TTL_SUBMISSIONS=3600   # 1 hour
SEC_EDGAR_CACHE_TTL_CIK_MAP=86400     # 24 hours

# ===========================================
# NASDAQ (free, no key required)
# ===========================================
NASDAQ_CACHE_TTL_EARNINGS=21600        # 6 hours
NASDAQ_EARNINGS_LOOKAHEAD_DAYS=14

# Finnhub (Stock Price Data)
# Get API key from https://finnhub.io (free tier: 60 calls/min)
FINNHUB_API_KEY=

# ===========================================
# API URLs (defaults are usually fine)
# ===========================================
POLYMARKET_GAMMA_API_URL=https://gamma-api.polymarket.com
FINNHUB_WS_URL=wss://ws.finnhub.io
FINNHUB_API_URL=https://finnhub.io/api/v1

# ===========================================
# TRADING
# ===========================================
TRADING_ENABLED=false
MAX_POSITION_SIZE=100.0
MIN_EDGE_THRESHOLD=0.05
CONFIDENCE_THRESHOLD=0.7

# ===========================================
# PROCESSING (Advanced)
# ===========================================
# Concurrency settings (defaults work well for most setups)
PROCESSING_WORKERS=5
PROCESSING_QUEUE_SIZE=100
WEB_SEARCH_MAX_QUERIES=2
POLYMARKET_MAX_KEYWORDS=5
