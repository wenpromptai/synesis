# ===========================================
# SYNESIS CONFIGURATION
# ===========================================
# Copy this file to .env and fill in your values
# Generate secrets with: openssl rand -hex 32

# Environment
SYNESIS_ENV=development
SYNESIS_DEBUG=true
SYNESIS_LOG_LEVEL=INFO

# ===========================================
# DATABASE (PostgreSQL + TimescaleDB)
# ===========================================
DB_PASSWORD=  # REQUIRED: Generate with: openssl rand -hex 32
DATABASE_URL=postgresql+asyncpg://synesis:${DB_PASSWORD}@localhost:5435/synesis

# ===========================================
# REDIS
# ===========================================
REDIS_PASSWORD=  # REQUIRED: Generate with: openssl rand -hex 32
REDIS_URL=redis://:${REDIS_PASSWORD}@localhost:6379

# ===========================================
# N8N (Workflow Automation)
# ===========================================
# Required for n8n encryption and JWT
N8N_ENCRYPTION_KEY=  # REQUIRED: Generate with: openssl rand -hex 32
N8N_USER_MANAGEMENT_JWT_SECRET=  # REQUIRED: Generate with: openssl rand -hex 32

# ===========================================
# TELEGRAM (Ingestion)
# ===========================================
# Get from https://my.telegram.org
TELEGRAM_API_ID=
TELEGRAM_API_HASH=
TELEGRAM_SESSION_NAME=synesis
TELEGRAM_CHANNELS=

# ===========================================
# TELEGRAM (Notifications)
# ===========================================
# Create a bot via @BotFather and get the token
# Get chat ID by messaging your bot and checking:
# https://api.telegram.org/bot<TOKEN>/getUpdates
TELEGRAM_BOT_TOKEN=
TELEGRAM_CHAT_ID=

# ===========================================
# TWITTER/X
# ===========================================
# Using TwitterAPI.io (or similar third-party provider)
TWITTERAPI_API_KEY=
TWITTER_API_BASE_URL=https://api.twitterapi.io
# JSON array of usernames to follow
TWITTER_ACCOUNTS=["DeItaone","KobeissiLetter","Fxhedgers","zerohedge"]

# Source categorization (affects urgency in Flow 1)
# News accounts = high urgency (breaking news, act fast)
TWITTER_NEWS_ACCOUNTS=["DeItaone","realDonaldTrump"]
# Analysis accounts = normal urgency (insights, consider)
TWITTER_ANALYSIS_ACCOUNTS=["elonmusk","NickTimiraos","charliebilello","KobeissiLetter"]

# ===========================================
# REDDIT (Flow 2 - Sentiment Intelligence)
# ===========================================
# JSON array of subreddits to monitor (no r/ prefix needed)
REDDIT_SUBREDDITS=["wallstreetbets","stocks","StockMarket","options","thetagang"]
REDDIT_POLL_INTERVAL=21600  # 6 hours in seconds

# ===========================================
# POLYMARKET
# ===========================================
POLYMARKET_API_KEY=
POLYMARKET_API_SECRET=
POLYMARKET_PRIVATE_KEY=
POLYMARKET_CHAIN_ID=137

# ===========================================
# KALSHI
# ===========================================
KALSHI_API_KEY=
KALSHI_PRIVATE_KEY_PATH=keys/kalshi-private-key.txt  # Download from Kalshi account settings

# ===========================================
# LLM PROVIDER
# ===========================================
# Provider: "anthropic" or "openai" (for ZAI, use "openai" with custom base URL)
LLM_PROVIDER=anthropic

# Anthropic (Claude)
ANTHROPIC_API_KEY=

# OpenAI / ZAI (OpenAI-compatible)
# For ZAI: set OPENAI_BASE_URL=https://api.z.ai/api/coding/paas/v4
OPENAI_API_KEY=
OPENAI_BASE_URL=

# Model names
# Anthropic: claude-3-5-haiku-20241022, claude-sonnet-4-20250514
# ZAI: glm-4.7, glm-4.7-FlashX, glm-4.7-Flash (free)
LLM_MODEL=claude-3-5-haiku-20241022
LLM_MODEL_SMART=claude-sonnet-4-20250514

# ===========================================
# WEB SEARCH (for LLM enrichment)
# ===========================================
# SearXNG (self-hosted, primary) - start with: docker compose up -d searxng
# No API key needed, no rate limits. Set to empty to disable.
SEARXNG_URL=http://localhost:8080
# Exa API - fallback for financial news (https://exa.ai)
EXA_API_KEY=
# Brave Search API - fallback (https://brave.com/search/api)
BRAVE_API_KEY=

# ===========================================
# CRAWL4AI (Web Crawling)
# ===========================================
# Start with: docker compose up -d crawl4ai
CRAWL4AI_URL=http://localhost:11235

# ===========================================
# SEC EDGAR (free, no key required)
# ===========================================
SEC_EDGAR_USER_AGENT=Synesis synesis@example.com
SEC_EDGAR_CACHE_TTL_SUBMISSIONS=3600   # 1 hour
SEC_EDGAR_CACHE_TTL_CIK_MAP=86400     # 24 hours

# ===========================================
# NASDAQ (free, no key required)
# ===========================================
NASDAQ_CACHE_TTL_EARNINGS=21600        # 6 hours
NASDAQ_EARNINGS_LOOKAHEAD_DAYS=14

# ===========================================
# DATA PROVIDERS
# ===========================================
# Provider selection (allows swapping data sources)
TICKER_PROVIDER=factset         # Options: factset, finnhub
FUNDAMENTALS_PROVIDER=factset  # Options: factset, finnhub, sec_edgar, none

# Finnhub (Stock Price Data)
# Get API key from https://finnhub.io (free tier: 60 calls/min)
FINNHUB_API_KEY=

# ===========================================
# FACTSET (SQL Server - Optional)
# ===========================================
# Only needed if using FactSet data feeds
SQLSERVER_HOST=
SQLSERVER_PORT=1433
SQLSERVER_DATABASE=
SQLSERVER_USER=
SQLSERVER_PASSWORD=

# ===========================================
# API URLs (defaults are usually fine)
# ===========================================
KALSHI_API_URL=https://api.elections.kalshi.com/trade-api/v2
KALSHI_WS_URL=wss://api.elections.kalshi.com/trade-api/ws/v2
POLYMARKET_GAMMA_API_URL=https://gamma-api.polymarket.com
POLYMARKET_DATA_API_URL=https://data-api.polymarket.com
POLYMARKET_CLOB_WS_URL=wss://ws-subscriptions-clob.polymarket.com/ws/market
FINNHUB_WS_URL=wss://ws.finnhub.io
FINNHUB_API_URL=https://finnhub.io/api/v1

# ===========================================
# MARKET INTELLIGENCE (Flow 3)
# ===========================================
MKT_INTEL_ENABLED=true
MKT_INTEL_INTERVAL=3600               # 1 hour scan cycle
MKT_INTEL_VOLUME_SPIKE_THRESHOLD=1.0   # 100% increase triggers spike
MKT_INTEL_INSIDER_SCORE_MIN=0.5
MKT_INTEL_EXPIRING_HOURS=24
MKT_INTEL_WS_ENABLED=true
MKT_INTEL_AUTO_WATCH_THRESHOLD=0.6
MKT_INTEL_UNWATCH_THRESHOLD=0.3

# ===========================================
# WATCHLIST INTELLIGENCE (Flow 4)
# ===========================================
WATCHLIST_INTEL_ENABLED=false
WATCHLIST_INTEL_INTERVAL=21600         # 6 hours
WATCHLIST_INTEL_EARNINGS_ALERT_DAYS=7
WATCHLIST_INTEL_MAX_TICKERS=30

# ===========================================
# TRADING
# ===========================================
TRADING_ENABLED=false
MAX_POSITION_SIZE=100.0
MIN_EDGE_THRESHOLD=0.05
CONFIDENCE_THRESHOLD=0.7

# ===========================================
# PROCESSING (Advanced)
# ===========================================
# Concurrency settings (defaults work well for most setups)
PROCESSING_WORKERS=5
PROCESSING_QUEUE_SIZE=100
WEB_SEARCH_MAX_QUERIES=2
POLYMARKET_MAX_KEYWORDS=5

# Output directory for signals
SIGNALS_OUTPUT_DIR=output/signals
